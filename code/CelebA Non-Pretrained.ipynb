{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDbJtpbFA-Zx"
   },
   "source": [
    "# Note on training:\n",
    "\n",
    "Rather than data being the image and target being the correct value, the data will be three images and the target will be which image is more similar to the first image.\n",
    "\n",
    "Create a custom dataset with PyTorch using the 3 images as the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17151,
     "status": "ok",
     "timestamp": 1621574446374,
     "user": {
      "displayName": "Danny Saad",
      "photoUrl": "",
      "userId": "08768728463630714575"
     },
     "user_tz": 240
    },
    "id": "_RRfisl-96d1",
    "outputId": "b008fde2-48ac-4086-b93a-e72035f4399d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.6/site-packages (0.10.24)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.6/site-packages (from wandb) (2.8.1)\n",
      "Requirement already satisfied: configparser>=3.8.1 in /opt/conda/lib/python3.6/site-packages (from wandb) (5.0.2)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.6/site-packages (from wandb) (5.3)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.6/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.6/site-packages (from wandb) (1.14.0)\n",
      "Requirement already satisfied: subprocess32>=3.5.3 in /opt/conda/lib/python3.6/site-packages (from wandb) (3.5.4)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /opt/conda/lib/python3.6/site-packages (from wandb) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from wandb) (2.22.0)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.6/site-packages (from wandb) (3.1.14)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.6/site-packages (from wandb) (5.6.7)\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.6/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: Click>=7.0 in /opt/conda/lib/python3.6/site-packages (from wandb) (7.1.1)\n",
      "Requirement already satisfied: sentry-sdk>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from wandb) (1.0.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.6/site-packages (from wandb) (3.15.6)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.0.0->wandb) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.0.0->wandb) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.0.0->wandb) (2019.11.28)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.6/site-packages (from GitPython>=1.0.0->wandb) (4.0.7)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /opt/conda/lib/python3.6/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (4.0.0)\n"
     ]
    }
   ],
   "source": [
    "# installs\n",
    "!pip install wandb\n",
    "\n",
    "# Library imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import wandb\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchviz import make_dot\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "from skimage import io, transform\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lKZimeron_zu"
   },
   "source": [
    "# Meta-criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 526,
     "status": "ok",
     "timestamp": 1621574475836,
     "user": {
      "displayName": "Danny Saad",
      "photoUrl": "",
      "userId": "08768728463630714575"
     },
     "user_tz": 240
    },
    "id": "4heO4Uo7Owze"
   },
   "outputs": [],
   "source": [
    "def metacriteria_attractive(A_attr: dict, B_attr: dict, C_attr: dict):\n",
    "  A_attractive = A_attr['Attractive']\n",
    "  B_attractive = B_attr['Attractive']\n",
    "  C_attractive = C_attr['Attractive']\n",
    "\n",
    "  if A_attractive == B_attractive:\n",
    "    if A_attractive == C_attractive:\n",
    "      return 0.5\n",
    "    return 1\n",
    "  if A_attractive == C_attractive:\n",
    "    return 0\n",
    "  return 0.5\n",
    "\n",
    "def metacriteria_similar_hair(a, b, c):\n",
    "  return 0\n",
    "\n",
    "def metacriteria_similar_facial_hair(a, b, c):\n",
    "  if(a == b and a != c):\n",
    "    return 1\n",
    "  if(a == b and a == c):\n",
    "    return 0.5\n",
    "  return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kpwVnA-oKgG"
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 747,
     "status": "ok",
     "timestamp": 1621574476541,
     "user": {
      "displayName": "Danny Saad",
      "photoUrl": "",
      "userId": "08768728463630714575"
     },
     "user_tz": 240
    },
    "id": "tsQfpCSWaEVQ",
    "outputId": "bb9e1f72-d402-492a-ae11-1ffe1271c900"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:3\n"
     ]
    }
   ],
   "source": [
    "# data settings:\n",
    "\n",
    "n_test = 5000\n",
    "# metacriteria = metacriteria_sameNumber\n",
    "batch_size=64 #input batch size for training (default: 64)\n",
    "batch_size_test=1000 \n",
    "\n",
    "\n",
    "# model settings\n",
    "epochs=40 #number of epochs to train (default: 14)\n",
    "lr=3 #learning rate (default: 1.0)\n",
    "gamma=0.7 #Learning rate step gamma (default: 0.7)\n",
    "seed=42 #random seed (default: 42)\n",
    "save_model=False #save the trained model (default: False)\n",
    "\n",
    "# misc settings\n",
    "no_cuda=False #disables CUDA training (default: True)\n",
    "use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device(3)\n",
    "kwargs = {'num_workers': 10, 'pin_memory': True}\n",
    "\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYQLa-J7Dl-d"
   },
   "source": [
    "### Data Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 2228,
     "status": "ok",
     "timestamp": 1621574478395,
     "user": {
      "displayName": "Danny Saad",
      "photoUrl": "",
      "userId": "08768728463630714575"
     },
     "user_tz": 240
    },
    "id": "qtWlI9ovDqtz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " 'code',\n",
       " 'docker',\n",
       " '.ipynb_checkpoints',\n",
       " 'wandb',\n",
       " 'vae.pt',\n",
       " '.gitignore',\n",
       " 'data',\n",
       " 'models',\n",
       " 'README.md']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Danny's Working Directory\n",
    "data_dir = 'data/celeba'\n",
    "encoder_path = 'models/celeba_encoder.pt'\n",
    "\n",
    "# Danny's CelebA Paths\n",
    "os.chdir('/home')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bREBMPnRuHsx"
   },
   "source": [
    "#CelebA Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPi-o2-UelWP"
   },
   "source": [
    "### Get Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-4_39uEuLxM"
   },
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 109626,
     "status": "ok",
     "timestamp": 1621574586980,
     "user": {
      "displayName": "Danny Saad",
      "photoUrl": "",
      "userId": "08768728463630714575"
     },
     "user_tz": 240
    },
    "id": "QpKeiYHTuPBc"
   },
   "outputs": [],
   "source": [
    "img_shape = (64, 64)\n",
    "\n",
    "# transforms\n",
    "tfms_train = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Resize(img_shape),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "tfms_val = tfms_test = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize(img_shape),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uR8uo8kIuSaz"
   },
   "source": [
    "###Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 108096,
     "status": "ok",
     "timestamp": 1621574586981,
     "user": {
      "displayName": "Danny Saad",
      "photoUrl": "",
      "userId": "08768728463630714575"
     },
     "user_tz": 240
    },
    "id": "tosmLkzRumPf"
   },
   "outputs": [],
   "source": [
    "class CelebA(Dataset):\n",
    "  def __init__(self, root_dir: str, partition: str, transform=None):\n",
    "    # the image data\n",
    "    self.img_dir = f\"{root_dir}/img_align_celeba\"\n",
    "\n",
    "    # the partition data\n",
    "    if partition=='train':\n",
    "      self.partition_ix = 0\n",
    "    elif partition=='val':\n",
    "      self.partition_ix = 1\n",
    "    elif partition=='test':\n",
    "      self.partition_ix = 2\n",
    "    else:\n",
    "      raise ValueError(\"partition must be one of 'train', 'val', or 'test'\")\n",
    "\n",
    "    df_partitions = pd.read_csv(f\"{root_dir}/list_eval_partition.csv\")\n",
    "    self.df_partitions = df_partitions[df_partitions['partition']==self.partition_ix]\n",
    "\n",
    "    # the attribute data\n",
    "    df_attributes = pd.read_csv(f\"{root_dir}/list_attr_celeba.csv\")\n",
    "\n",
    "    # filter the attributes\n",
    "    self.df_attributes = self.df_partitions.merge(df_attributes, how='left', on='image_id').drop(columns=['partition'])\n",
    "\n",
    "    # transforms\n",
    "    self.transform = transform\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.df_attributes.shape[0]\n",
    "\n",
    "  def __getitem__(self, ix):\n",
    "    # image\n",
    "    filepath = f\"{self.img_dir}/{self.df_attributes.image_id[ix]}\"\n",
    "    image = Image.open(filepath)\n",
    "    if self.transform:\n",
    "      image = self.transform(image)\n",
    "\n",
    "    # attributes\n",
    "    attributes =self.df_attributes.iloc[ix, 1:].to_dict()\n",
    "\n",
    "    return {'image': image, 'attributes': attributes}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IYA_iyl2b5dt"
   },
   "source": [
    "#Triplet dataset class\n",
    "Where the inputs are:\n",
    "*   List of triple indices to use for training\n",
    "*   Original training set\n",
    "*   Function for evaluating meta-criteria\n",
    "\n",
    "And the output is:\n",
    "*   ((A: image,B: image,C: image), target: bool)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRRR6V5ipXvv"
   },
   "source": [
    "### Defining the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 107290,
     "status": "ok",
     "timestamp": 1621574586981,
     "user": {
      "displayName": "Danny Saad",
      "photoUrl": "",
      "userId": "08768728463630714575"
     },
     "user_tz": 240
    },
    "id": "n36_Tzi5sHim"
   },
   "outputs": [],
   "source": [
    "class ImageTripletDataset(Dataset):\n",
    "    \"\"\"Dataset of triplets of images\"\"\"\n",
    "\n",
    "    def __init__(self, ImageDataset, num_triplets, criteria):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            ImageDataset (torch.utils.data.Dataset):  A pytorch dataset that serves individual images\n",
    "            num_triplets (int): Number of triplets\n",
    "        \"\"\"\n",
    "        self.imagedataset=ImageDataset\n",
    "        self.num_triplets = num_triplets\n",
    "        self.criteria = criteria\n",
    "\n",
    "        # generate indices list\n",
    "        self.indices = np.random.randint(0, len(self.imagedataset), (self.num_triplets, 3))\n",
    "        # TODO: make sure there are no duplicates?\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_triplets\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        Aix, Bix, Cix = self.indices[idx]\n",
    "\n",
    "        A = self.imagedataset[Aix]\n",
    "        B = self.imagedataset[Bix]\n",
    "        C = self.imagedataset[Cix]\n",
    "\n",
    "        A_img, A_attr = A['image'], A['attributes']\n",
    "        B_img, B_attr = B['image'], B['attributes']\n",
    "        C_img, C_attr = C['image'], C['attributes']\n",
    "\n",
    "        sample = {'A': A_img, 'B': B_img, 'C':C_img, \n",
    "                  'target': self.criteria(A_attr,B_attr,C_attr),\n",
    "                  'image_indices': (Aix, Bix, Cix), 'image_digits': (A_attr, B_attr, C_attr)}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-I16_W26paIC"
   },
   "source": [
    "### Creating datasets/dataloaders for training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4XUJvI5St35"
   },
   "source": [
    "# VAE Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JdF5QzZfQp4c"
   },
   "source": [
    "### Encoder \n",
    "VAE Encoder copied from a separate VAE Training Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 105889,
     "status": "ok",
     "timestamp": 1621574586981,
     "user": {
      "displayName": "Danny Saad",
      "photoUrl": "",
      "userId": "08768728463630714575"
     },
     "user_tz": 240
    },
    "id": "ZpuDa2yWQ9rs"
   },
   "outputs": [],
   "source": [
    "# add faces encoder\n",
    "# encoder class copied from VAE notebook\n",
    "class Encoder(nn.Module):\n",
    "  def __init__(self, coarse_resolution = (4,4), hid_channels=(8, 12, 16)):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.coarse_resolution = coarse_resolution\n",
    "    \n",
    "    # block 1:\n",
    "    self.block1 = nn.Sequential(OrderedDict(\n",
    "      conv = nn.Conv2d(in_channels=1, out_channels=hid_channels[0], kernel_size=5, stride=1, padding=2, bias=False),\n",
    "      bn = nn.BatchNorm2d(hid_channels[0]),\n",
    "      relu = nn.ReLU(),\n",
    "      pool = nn.MaxPool2d(2)\n",
    "    ))\n",
    "\n",
    "    # block 2:\n",
    "    self.block2 = nn.Sequential(OrderedDict(\n",
    "      conv = nn.Conv2d(in_channels=hid_channels[0], out_channels=hid_channels[1], kernel_size=3, stride=1, padding=1, bias=False),\n",
    "      bn = nn.BatchNorm2d(num_features=hid_channels[1]),\n",
    "      relu = nn.ReLU(),\n",
    "      pool = nn.MaxPool2d(2)\n",
    "    ))\n",
    "\n",
    "    # block 3:\n",
    "    self.block3 = nn.Sequential(OrderedDict(\n",
    "      conv = nn.Conv2d(in_channels=hid_channels[1], out_channels=hid_channels[2], kernel_size=3, stride=1, padding=1, bias=False),\n",
    "      bn = nn.BatchNorm2d(num_features=hid_channels[2]),\n",
    "      relu = nn.ReLU(),\n",
    "      pool = nn.AdaptiveAvgPool2d(output_size=self.coarse_resolution),\n",
    "      flatten = nn.Flatten()\n",
    "    ))\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.block1(x)\n",
    "    x = self.block2(x)\n",
    "    z = self.block3(x)\n",
    "\n",
    "    return(z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BRhh29oIR1Np"
   },
   "source": [
    "### Decoder \n",
    "VAE Decoder copied from a separate VAE Training Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 105494,
     "status": "ok",
     "timestamp": 1621574586982,
     "user": {
      "displayName": "Danny Saad",
      "photoUrl": "",
      "userId": "08768728463630714575"
     },
     "user_tz": 240
    },
    "id": "d7AP2Si9R8pe"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "  def __init__(self, coarse_resolution = (4,4), hid_channels=(16, 12, 8)):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.coarse_resolution = coarse_resolution\n",
    "    self.zdim = hid_channels[0]*self.coarse_resolution[0]*self.coarse_resolution[1]\n",
    "    \n",
    "    # block 1:\n",
    "    self.block1 = nn.Sequential(OrderedDict(\n",
    "      unflatten = nn.Unflatten(-1, (hid_channels[0], self.coarse_resolution[0], self.coarse_resolution[1])),\n",
    "      conv = nn.Conv2d(in_channels=hid_channels[0], out_channels=hid_channels[1], kernel_size=3, stride=1, padding=1, bias=False),\n",
    "      bn = nn.BatchNorm2d(hid_channels[1]),\n",
    "      relu = nn.ReLU(),\n",
    "      upsample = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "    ))\n",
    "\n",
    "    # block 2:\n",
    "    self.block2 = nn.Sequential(OrderedDict(\n",
    "      conv = nn.Conv2d(in_channels=hid_channels[1], out_channels=hid_channels[2], kernel_size=3, stride=1, padding=1, bias=False),\n",
    "      bn = nn.BatchNorm2d(num_features=hid_channels[2]),\n",
    "      relu = nn.ReLU(),\n",
    "      upsample = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "    ))\n",
    "\n",
    "    # block 3:\n",
    "    self.block3 = nn.Sequential(OrderedDict(\n",
    "      conv = nn.Conv2d(in_channels=hid_channels[2], out_channels=hid_channels[2], kernel_size=3, stride=1, padding=1, bias=False),\n",
    "      bn = nn.BatchNorm2d(num_features=hid_channels[2]),\n",
    "      relu = nn.ReLU(),\n",
    "      upsample = nn.UpsamplingBilinear2d(size=(28, 28))\n",
    "    ))\n",
    "\n",
    "    # touch-up \n",
    "    self.touchup = nn.Sequential(OrderedDict(\n",
    "        conv = nn.Conv2d(in_channels=hid_channels[2], out_channels=1, kernel_size=3, stride=1, padding=1),\n",
    "        sig = nn.Sigmoid()\n",
    "    ))\n",
    "\n",
    "  def forward(self, z):\n",
    "    z = self.block1(z)\n",
    "    z = self.block2(z)\n",
    "    z = self.block3(z)\n",
    "    x = self.touchup(z)\n",
    "\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWbJHb3_ozKU"
   },
   "source": [
    "# Triplet model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6mzuWAqzqBiA"
   },
   "source": [
    "### Triplet probability class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 104460,
     "status": "ok",
     "timestamp": 1621574586982,
     "user": {
      "displayName": "Danny Saad",
      "photoUrl": "",
      "userId": "08768728463630714575"
     },
     "user_tz": 240
    },
    "id": "jBlDnltUp9r9"
   },
   "outputs": [],
   "source": [
    "# From Van der Maaten: https://ieeexplore.ieee.org/abstract/document/6349720/?casa_token=_dWfybjO5O4AAAAA:T4Al2g3ZWaHcRwCzlp9QqRji1amJ-uCHwbEyAOHk3_AH9uIGjs4iBFaUf8XO-wqLpd7D2BH1eQ\n",
    "# this has 0 free parameters\n",
    "class TripletProbability(nn.Module):\n",
    "  def __init__(self, alpha):\n",
    "    super(TripletProbability, self).__init__()\n",
    "    self.alpha=alpha\n",
    "\n",
    "  def t_dist(self, d):\n",
    "    return (1+d**2/self.alpha)**(-1*(self.alpha+1)/2)\n",
    "  \n",
    "  def forward(self, dAB, dAC):\n",
    "    tAB = self.t_dist(dAB)\n",
    "    tAC = self.t_dist(dAC)\n",
    "    return tAB / (tAB + tAC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "veC09SWTqTV5"
   },
   "source": [
    "### Pairwise-distance neural network module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 103633,
     "status": "ok",
     "timestamp": 1621574586982,
     "user": {
      "displayName": "Danny Saad",
      "photoUrl": "",
      "userId": "08768728463630714575"
     },
     "user_tz": 240
    },
    "id": "6GSBvQCGqccC"
   },
   "outputs": [],
   "source": [
    "class PairwiseDistance(nn.Module):\n",
    "  def __init__(self, n_hid):\n",
    "    super(PairwiseDistance, self).__init__()\n",
    "    self.n_hid = n_hid\n",
    "\n",
    "    self.f = nn.Sequential(\n",
    "        nn.Linear(2*self.n_hid, self.n_hid),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(self.n_hid,1)\n",
    "    )\n",
    "  \n",
    "  def forward(self, A, B):\n",
    "    # A: [batch_size, n_hid]\n",
    "    # B: [batch_size, n_hid]\n",
    "    print(\"A Size: \", A.shape)\n",
    "    AB = torch.cat([A, B], dim=1)\n",
    "    print(\"AB Size: \", AB.shape)\n",
    "    squeezed = self.f(AB).squeeze()\n",
    "    print(\"Squeezed AB Size: \", squeezed.shape)\n",
    "    return squeezed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZuXiuebq1oW"
   },
   "source": [
    "### TripletNet \n",
    "A neural network for modeling whether or not a triplet of images, (A, B, C), \n",
    "satisfies the proposition \"A is more similar to B than C\" according to a meta-\n",
    "criteria. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 102588,
     "status": "ok",
     "timestamp": 1621574587234,
     "user": {
      "displayName": "Danny Saad",
      "photoUrl": "",
      "userId": "08768728463630714575"
     },
     "user_tz": 240
    },
    "id": "dZuR-N5Jrrm8"
   },
   "outputs": [],
   "source": [
    "class TripletNet(nn.Module):\n",
    "    def __init__(self, n_hid=10, alpha=1):\n",
    "        super(TripletNet, self).__init__()\n",
    "\n",
    "        self.n_hid=n_hid\n",
    "        self.alpha=alpha\n",
    "\n",
    "        # feature encoder\n",
    "        # resuse for each input image\n",
    "        self.encoder = Encoder()\n",
    "        \n",
    "        # distance computer: takes two samples and computes a distance\n",
    "        # reuse this for pairs (A, B) and (A, C)\n",
    "        # can make this more complex or more simple in future\n",
    "        self.pairwise_distance = PairwiseDistance(n_hid=self.n_hid)\n",
    "\n",
    "        # triplet probability computer defined in the class above\n",
    "        self.triplet_probability = TripletProbability(self.alpha)\n",
    "        \n",
    "    def forward(self, A, B, C):\n",
    "        # first compute all of the encodings\n",
    "        A, B, C = [self.encoder(x) for x in (A,B,C)]\n",
    "        \n",
    "        # then get the pairwise distances\n",
    "        dAB = self.pairwise_distance(A, B)\n",
    "        dAC = self.pairwise_distance(A, C)\n",
    "\n",
    "        # finally return the triplet probability\n",
    "        return self.triplet_probability(dAB, dAC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8et6eIMcY8E"
   },
   "source": [
    "# Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 101519,
     "status": "ok",
     "timestamp": 1621574587234,
     "user": {
      "displayName": "Danny Saad",
      "photoUrl": "",
      "userId": "08768728463630714575"
     },
     "user_tz": 240
    },
    "id": "RYKoSAKLJODw"
   },
   "outputs": [],
   "source": [
    "#@title Training and testing functions\n",
    "def train(model, criteria, device, loader, optimizer):\n",
    "  model.train()\n",
    "\n",
    "  mean_batch_losses = []\n",
    "  for batch_idx, batch_dict in enumerate(loader):\n",
    "    A, B, C, target = [batch_dict[key].to(device) for key in [\"A\", \"B\", \"C\", \"target\"]]\n",
    "    optimizer.zero_grad()\n",
    "    output = model(A,B,C)\n",
    "    break\n",
    "    loss = criteria(output.float(), target.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    mean_batch_losses.append(loss.item())\n",
    "        \n",
    "  return np.mean(mean_batch_losses)\n",
    "\n",
    "            \n",
    "def test(model, criteria, device, loader):\n",
    "    model.eval()\n",
    "\n",
    "    mean_batch_losses = []\n",
    "    outputs = []\n",
    "    targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch_dict in enumerate(loader):\n",
    "          A, B, C, target = [batch_dict[key].to(device) for key in [\"A\", \"B\", \"C\", \"target\"]]\n",
    "          output = model(A, B, C)\n",
    "          loss = criteria(output.float(), target.float()) \n",
    "\n",
    "          # store results\n",
    "          mean_batch_losses.append(loss.item())\n",
    "          outputs.append(output)\n",
    "          targets.append(target)\n",
    "\n",
    "    outputs = torch.cat(outputs)\n",
    "    targets = torch.cat(targets)\n",
    "\n",
    "\n",
    "    \n",
    "    return np.mean(mean_batch_losses), outputs, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d5J1Rvt1-tyJ"
   },
   "source": [
    "# TRAINING LOOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJWyPMC79S1V"
   },
   "source": [
    "### Loop Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 100106,
     "status": "ok",
     "timestamp": 1621574587478,
     "user": {
      "displayName": "Danny Saad",
      "photoUrl": "",
      "userId": "08768728463630714575"
     },
     "user_tz": 240
    },
    "id": "hJWMoHL19dl5"
   },
   "outputs": [],
   "source": [
    "def makeData(n_train, metacriteria):\n",
    "  #training data\n",
    " # image_dataset_train = dataPath\n",
    "  image_dataset_train = CelebA(data_dir, \"train\", transform = tfms_train)\n",
    "  triplet_dataset_train = ImageTripletDataset(image_dataset_train, n_train, metacriteria)\n",
    "  train_loader = torch.utils.data.DataLoader(\n",
    "      triplet_dataset_train,\n",
    "      batch_size=batch_size, shuffle=True, **kwargs)\n",
    "    \n",
    "  # testing data\n",
    "  image_dataset_test = CelebA(data_dir, \"test\", transform = tfms_test)\n",
    "  triplet_dataset_test = ImageTripletDataset(image_dataset_test, n_test, metacriteria)\n",
    "  test_loader = torch.utils.data.DataLoader(\n",
    "      triplet_dataset_test,\n",
    "      batch_size=batch_size_test, shuffle=True, **kwargs)\n",
    "    \n",
    "  return train_loader,test_loader\n",
    "\n",
    "\n",
    "\n",
    "def makeModel():\n",
    "  model = TripletNet(n_hid=256).to(device)\n",
    "  return model\n",
    "\n",
    "\n",
    "\n",
    "def getLowestError(model, train_loader, test_loader):\n",
    "  optimizer = optim.Adadelta(model.parameters(), lr=lr)\n",
    "  scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "  criteria = nn.BCELoss()\n",
    "\n",
    "  best_test = 10**10\n",
    "  best_train = 10**10\n",
    "  best_auroc_filtered = 0.5\n",
    "  best_auroc_all = 0.5\n",
    "  best_accuracy_all = 0.5\n",
    "  best_accuracy_filtered = 0.5\n",
    "  best_epoch = 0\n",
    "  for epoch in range(1, epochs + 1):\n",
    "    train_loss = train(model, criteria, device, train_loader, optimizer)\n",
    "    test_loss, outputs, targets = test(model, criteria, device, test_loader)\n",
    "    scheduler.step()\n",
    "\n",
    "    auroc_filtered = getAUROC_filtered(outputs, targets)\n",
    "    auroc_all = getAUROC_all(outputs, targets)\n",
    "    accuracy_filtered = getAccuracy_filtered(outputs, targets)\n",
    "    accuracy_all = getAccuracy_all(outputs,targets)\n",
    "    \n",
    "    print(\"Train Loss: %0.3f. Test Loss: %0.3f. AUROC_Filtered: %0.3f. AUROC_All: %0.3f. Accuracy Filtered: %0.3f. Accuracy All: %0.3f. Epoch: %i\" % (train_loss, test_loss, auroc_filtered, auroc_all, accuracy_filtered, accuracy_all, epoch))\n",
    "    if test_loss<best_test:\n",
    "      best_test = test_loss\n",
    "      best_train = train_loss.item()\n",
    "      best_auroc_filtered = auroc_filtered\n",
    "      best_auroc_all = auroc_all\n",
    "      best_accuracy_filtered = accuracy_filtered\n",
    "      best_accuracy_all = accuracy_all\n",
    "      best_epoch = epoch\n",
    "    if epoch > best_epoch + 5:\n",
    "      break\n",
    "\n",
    "  #return best_test, best_auroc, best_epoch\n",
    "  return best_test, best_epoch, best_accuracy_all, best_accuracy_filtered, best_auroc_filtered, best_auroc_all\n",
    "\n",
    "def getAUROC_filtered(outputs, targets):\n",
    "  ix_keep = targets!=0.5\n",
    "  filteredOutputs = outputs[ix_keep]\n",
    "  filteredTargets = targets[ix_keep]\n",
    "  return roc_auc_score(filteredTargets.cpu().numpy(), filteredOutputs.cpu().numpy())\n",
    "\n",
    "def getAUROC_all(outputs, targets):\n",
    "  predictions = outputs.cpu().numpy()\n",
    "  targets = targets.cpu().numpy()\n",
    "  binned_predictions = []\n",
    "  binned_targets = []\n",
    "\n",
    "  bins = [0, 1/2, 1]\n",
    "  bin_indices = np.digitize(predictions, bins)\n",
    "  for index in bin_indices:\n",
    "    if index == 1:\n",
    "      binned_predictions.append(0)\n",
    "    elif index == 2:\n",
    "      binned_predictions.append(1)\n",
    "\n",
    "  bin_indices = np.digitize(targets, bins)\n",
    "  for target in targets:\n",
    "    if target == 0:\n",
    "      binned_targets.append(0)\n",
    "    elif target == 0.5:\n",
    "      binned_targets.append(1)\n",
    "    elif target == 1:\n",
    "      binned_targets.append(1)\n",
    "  \n",
    "  return roc_auc_score(binned_targets, binned_predictions)\n",
    "\n",
    "def getAccuracy_filtered(outputs, targets):\n",
    "  ix_keep = targets!=0.5\n",
    "  filteredOutputs = outputs[ix_keep]\n",
    "  filteredTargets = targets[ix_keep]\n",
    "  filteredOutputs = filteredOutputs.cpu().numpy()\n",
    "  filteredTargets = filteredTargets.cpu().numpy()\n",
    "\n",
    "  correct = 0;\n",
    "  results = np.equal(filteredOutputs, filteredTargets)\n",
    "  for result in results:\n",
    "    if result:\n",
    "      correct += 1\n",
    "  \n",
    "  return (correct / filteredTargets.size)\n",
    "\n",
    "\n",
    "def getAccuracy_all(predictions, targets):\n",
    "  predictions = predictions.cpu().numpy()\n",
    "  targets = targets.cpu().numpy()\n",
    "  new_predictions = []\n",
    "  correct = 0\n",
    "\n",
    "  bins = [0, 1/3, 2/3, 1]\n",
    "  bin_indices = np.digitize(predictions, bins)\n",
    "  for index in bin_indices:\n",
    "    if index == 1:\n",
    "      new_predictions.append(0)\n",
    "    elif index == 2:\n",
    "      new_predictions.append(0.5)\n",
    "    elif index == 3:\n",
    "      new_predictions.append(1)\n",
    "  \n",
    "  results = np.equal(new_predictions,targets)\n",
    "  for result in results:\n",
    "    if result:\n",
    "      correct += 1\n",
    "  \n",
    "  return (correct / predictions.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZE73sPOwTRWp"
   },
   "source": [
    "### The Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "4e37a7d950934142814cf90c380433a1",
      "2a71d790909e43fd8732382e36019371",
      "3d47fdec9b2248cc9f68602baef4f674",
      "54987a9a31994802ac7db2bcba1f8d0f",
      "1bf80c5be0a545c69e31f37ec7a00719",
      "348285d4d0784f27a384cb4dcec7b60a",
      "8d5ee593cd19475d80c8315caf097793",
      "c3e0cbe4cfcb4c1baa0f5f250da5a4d6"
     ]
    },
    "executionInfo": {
     "elapsed": 3426967,
     "status": "ok",
     "timestamp": 1621578014463,
     "user": {
      "displayName": "Danny Saad",
      "photoUrl": "",
      "userId": "08768728463630714575"
     },
     "user_tz": 240
    },
    "id": "GsbvPLEK-2d5",
    "outputId": "f36a041e-c485-45da-d55c-d3a1cfca4fbe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:30xgokwn) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 52215<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/wandb/run-20210525_153413-30xgokwn/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/wandb/run-20210525_153413-30xgokwn/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">peachy-armadillo-378</strong>: <a href=\"https://wandb.ai/witw/qualitative-analysis/runs/30xgokwn\" target=\"_blank\">https://wandb.ai/witw/qualitative-analysis/runs/30xgokwn</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:30xgokwn). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.30 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.24<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">earnest-flower-381</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/witw/qualitative-analysis\" target=\"_blank\">https://wandb.ai/witw/qualitative-analysis</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/witw/qualitative-analysis/runs/2yvke6yr\" target=\"_blank\">https://wandb.ai/witw/qualitative-analysis/runs/2yvke6yr</a><br/>\n",
       "                Run data is saved locally in <code>/home/wandb/run-20210525_154703-2yvke6yr</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING SIZE: %i 100\n",
      "A Size:  torch.Size([64, 256])\n",
      "AB Size:  torch.Size([64, 512])\n",
      "Squeezed AB Size:  torch.Size([64])\n",
      "A Size:  torch.Size([64, 256])\n",
      "AB Size:  torch.Size([64, 512])\n",
      "Squeezed AB Size:  torch.Size([64])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-c0a69f5f7f45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m#test model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mbest_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_accuracy_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_accuracy_filtered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_auroc_filtered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_auroc_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetLowestError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     wandb.log({'Datasize': n_train,\n\u001b[1;32m     22\u001b[0m                \u001b[0;34m'Test_Loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbest_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-a95fde3d6d68>\u001b[0m in \u001b[0;36mgetLowestError\u001b[0;34m(model, train_loader, test_loader)\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-f611f4842963>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, criteria, device, loader)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dict\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m           \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"A\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"target\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m           \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "metacriteria_list = [metacriteria_attractive]                    \n",
    "trainingSize = np.logspace(2, 3.69897000434, 15).astype(np.int)\n",
    "\n",
    "\n",
    "for metacriteria in metacriteria_list:\n",
    "\n",
    "  run = wandb.init(project='qualitative-analysis', entity='witw', config = {\n",
    "        \"metacriteria\": metacriteria.__name__, \"pretrained\": False}, reinit = True)\n",
    "  wandb.run.name = \"CELEBA6-n_pretrained\" + metacriteria.__name__ \n",
    "\n",
    "  for n_train in trainingSize:\n",
    "    \n",
    "    print(\"TRAINING SIZE: %i\", n_train)\n",
    "    train_loader,test_loader = makeData(n_train, metacriteria)\n",
    "    \n",
    "    # make model\n",
    "    model = makeModel()\n",
    "    \n",
    "    #test model\n",
    "    best_test, best_epoch, best_accuracy_all, best_accuracy_filtered, best_auroc_filtered, best_auroc_all = getLowestError(model,train_loader,test_loader)\n",
    "    wandb.log({'Datasize': n_train,\n",
    "               'Test_Loss': best_test, \n",
    "               'AUROC_filtered': best_auroc_filtered, \n",
    "               'Accuracy_filtered': best_accuracy_filtered, \n",
    "               'Accuracy_all': best_accuracy_all, \n",
    "               'Epoch': best_epoch})\n",
    "    \n",
    "    print(\"Datasize: %i\", n_train)    \n",
    "    print(\"Best Test Loss: %0.3f. Best AUROC Filtered: %0.3f. Best AUROC All: %0.3f. Best Accuracy Filtered: %0.3f. Best Accuracy All: %0.3f. Best Epoch: %i\\n\" % (best_test, best_auroc_filtered, best_auroc_all, best_accuracy_filtered, best_accuracy_all, best_epoch))\n",
    "\n",
    "\n",
    "    if save_model:\n",
    "        torch.save(model.state_dict(), \"mnist_flat.pt\")\n",
    "\n",
    "  run.finish()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "executionInfo": {
     "elapsed": 3083585,
     "status": "ok",
     "timestamp": 1619068282234,
     "user": {
      "displayName": "Danny Saad",
      "photoUrl": "",
      "userId": "08768728463630714575"
     },
     "user_tz": 240
    },
    "id": "6VBP3TGXCFSC",
    "outputId": "06e87a17-bd44-4b11-9b97-e89d6de11909"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ERPHXp06IaqH"
   },
   "source": [
    "# Visualize the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mTF9_SKlsR0i"
   },
   "outputs": [],
   "source": [
    "def get_encodings(model, device, loader):\n",
    "    model.eval()\n",
    "\n",
    "    outputs = []\n",
    "    targets = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (img, target) in enumerate(loader):\n",
    "          output = model(img.to(device))\n",
    "          outputs.append(output)\n",
    "          targets.append(target)\n",
    "\n",
    "    outputs = torch.cat(outputs)\n",
    "    targets = torch.cat(targets)\n",
    "\n",
    "    \n",
    "    return outputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "executionInfo": {
     "elapsed": 3084132,
     "status": "error",
     "timestamp": 1619068282812,
     "user": {
      "displayName": "Danny Saad",
      "photoUrl": "",
      "userId": "08768728463630714575"
     },
     "user_tz": 240
    },
    "id": "0kj5F6ATKzld",
    "outputId": "1fd52402-9c75-4e31-8abd-6aa66ba49adb"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-033404872640>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m image_loader_test = torch.utils.data.DataLoader(\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mimage_dataset_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     batch_size=batch_size_test, shuffle=True, **kwargs)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_dataset_test' is not defined"
     ]
    }
   ],
   "source": [
    "encoder = model.encoder\n",
    "image_loader_test = torch.utils.data.DataLoader(\n",
    "    image_dataset_test,\n",
    "    batch_size=batch_size_test, shuffle=True, **kwargs)\n",
    "\n",
    "outputs, targets = get_encodings(encoder, device, image_loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-_Etxs3bLA3J"
   },
   "outputs": [],
   "source": [
    "test_embeddings = outputs.cpu().numpy()\n",
    "targets = targets.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qgkxfkp_0UR_"
   },
   "outputs": [],
   "source": [
    "reducer = umap.UMAP()\n",
    "embedding = reducer.fit_transform(test_embeddings)\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iA7UbJQr0jxd"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "sns.scatterplot(x=embedding[:,0], y=embedding[:,1], hue=targets.astype(str), hue_order=[str(i) for i in range(10)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cHUOtR9QzJRD"
   },
   "outputs": [],
   "source": [
    "pd.concat([pd.DataFrame(embedding), pd.DataFrame(targets)], axis = 1).to_csv(dataPath + \"least_common_multiple_UMAP.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wAbZ-9Yj0sxl"
   },
   "outputs": [],
   "source": [
    "def experiment_criteria(metacriteria, epochs=3, dataset_train=False, dataset_test=False, n_train=50000, n_test=5000, batch_size=64,batch_size_test=1000, UMAP=True):\n",
    "  #settings\n",
    "  lr=1\n",
    "  gamma=0.7\n",
    "  seed=42\n",
    "  no_cuda=False\n",
    "  use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "  torch.manual_seed(seed)\n",
    "  device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "  kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "  if not dataset_train and dataset_test:\n",
    "    #download training data if not included\n",
    "    dataset_train = datasets.MNIST('../data', train=True, download=True,\n",
    "                    transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ]))\n",
    "    # download testing data if not included\n",
    "    dataset_test = datasets.MNIST('../data', train=False, download=True,\n",
    "                    transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ]))\n",
    "  #train data\n",
    "  triplet_dataset_train = ImageTripletDataset(dataset_train, n_train, metacriteria)\n",
    "  train_loader = torch.utils.data.DataLoader(\n",
    "    triplet_dataset_train,\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "  \n",
    "  #test data\n",
    "  triplet_dataset_test = ImageTripletDataset(dataset_test, n_test, metacriteria)\n",
    "  test_loader = torch.utils.data.DataLoader(\n",
    "    triplet_dataset_test,\n",
    "    batch_size=batch_size_test, shuffle=True, **kwargs)\n",
    "  \n",
    "  model = TripletNet().to(device)\n",
    "\n",
    "  optimizer = optim.Adadelta(model.parameters(), lr=lr)\n",
    "  scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "  criteria = nn.BCELoss()\n",
    "\n",
    "  for epoch in range(1, epochs + 1):\n",
    "    train_loss = train(model, criteria, device, train_loader, optimizer)\n",
    "    test_loss, outputs, targets = test(model, criteria, device, test_loader)\n",
    "    scheduler.step()\n",
    "\n",
    "    roc_auc = roc_auc_score(targets.cpu().numpy(), outputs.cpu().numpy())\n",
    "\n",
    "    print(\"Train loss: %0.3f. Test loss: %0.3f. AUROC: %0.3f\" % (train_loss, test_loss, roc_auc))\n",
    "\n",
    "  if UMAP:\n",
    "    encoder = model.encoder\n",
    "    image_loader_test = torch.utils.data.DataLoader(\n",
    "      dataset_test,\n",
    "      batch_size=batch_size_test, shuffle=True, **kwargs)\n",
    "\n",
    "    outputs, targets = get_encodings(encoder, device, image_loader_test)\n",
    "    \n",
    "    test_embeddings = outputs.cpu().numpy()\n",
    "    targets = targets.cpu().numpy() \n",
    "\n",
    "    reducer = umap.UMAP()\n",
    "    embedding = reducer.fit_transform(test_embeddings)\n",
    "    embedding.shape\n",
    "\n",
    "    plt.figure(figsize=(15,15))\n",
    "    sns.scatterplot(x=embedding[:,0], y=embedding[:,1], hue=targets.astype(str), hue_order=[str(i) for i in range(10)])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EuLcX5_Gt3U0"
   },
   "outputs": [],
   "source": [
    "experiment_criteria(metacriteria_least_common_multiple, epochs=6,dataset_train=image_dataset_train, dataset_test=image_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cn3CrrJ07Zln"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CelebA Pretrained.ipynb",
   "provenance": [
    {
     "file_id": "1igpQstq1G3LvqRQqRZzzUhFIe2QgAgZI",
     "timestamp": 1614657191714
    },
    {
     "file_id": "137A9pWv-ypkT5E2qd4eCk8mgQJUwR8o1",
     "timestamp": 1604258134579
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1bf80c5be0a545c69e31f37ec7a00719": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a71d790909e43fd8732382e36019371": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "348285d4d0784f27a384cb4dcec7b60a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d47fdec9b2248cc9f68602baef4f674": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_348285d4d0784f27a384cb4dcec7b60a",
      "placeholder": "",
      "style": "IPY_MODEL_1bf80c5be0a545c69e31f37ec7a00719",
      "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r"
     }
    },
    "4e37a7d950934142814cf90c380433a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3d47fdec9b2248cc9f68602baef4f674",
       "IPY_MODEL_54987a9a31994802ac7db2bcba1f8d0f"
      ],
      "layout": "IPY_MODEL_2a71d790909e43fd8732382e36019371"
     }
    },
    "54987a9a31994802ac7db2bcba1f8d0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c3e0cbe4cfcb4c1baa0f5f250da5a4d6",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8d5ee593cd19475d80c8315caf097793",
      "value": 1
     }
    },
    "8d5ee593cd19475d80c8315caf097793": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c3e0cbe4cfcb4c1baa0f5f250da5a4d6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
